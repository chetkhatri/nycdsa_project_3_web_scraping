{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_1 = \"https://www.tripadvisor.com/Search?geo=191&redirect&q=national+park&uiOrigin=MASTHEAD&ssrc=A&typeaheadRedirect=true&returnTo=__2F__Travel__2D__g191__2D__c3259__2F__United__2D__States%3ANational__2E__Parks__2E__Monuments__2E__Etc__2E__html__2F__&pid=3825&startTime=undefined&searchSessionId=52A513F08A52B338445106C616C0147C1480475706599ssid#&o=0\"\n",
    "# url_2 = \"https://www.tripadvisor.com/Search?geo=191&redirect&q=national+park&uiOrigin=MASTHEAD&ssrc=a&typeaheadRedirect=true&returnTo=__2F__Travel__2D__g191__2D__c3259__2F__United__2D__States%3ANational__2E__Parks__2E__Monuments__2E__Etc__2E__html__2F__&pid=3825&startTime=undefined&searchSessionId=CE0A01169CA97378CAFBC24D9829C7A41481686374068ssid&sid=CE0A01169CA97378CAFBC24D9829C7A41481689024838&rf=0&sessionId=CE0A01169CA97378CAFBC24D9829C7A4&actionType=updatePage&dist=undefined&o=30&ajax=search\"\n",
    "# url_3 = \"https://www.tripadvisor.com/Search?geo=191&redirect&q=national+park&uiOrigin=MASTHEAD&ssrc=a&typeaheadRedirect=true&returnTo=__2F__Travel__2D__g191__2D__c3259__2F__United__2D__States%3ANational__2E__Parks__2E__Monuments__2E__Etc__2E__html__2F__&pid=3825&startTime=undefined&searchSessionId=CE0A01169CA97378CAFBC24D9829C7A41481686374068ssid&sid=CE0A01169CA97378CAFBC24D9829C7A41481689024838&rf=0&sessionId=CE0A01169CA97378CAFBC24D9829C7A4&actionType=updatePage&dist=undefined&o=60&ajax=search\"\n",
    "# url_4 = \"https://www.tripadvisor.com/Search?geo=191&redirect&q=national+park&uiOrigin=MASTHEAD&ssrc=a&typeaheadRedirect=true&returnTo=__2F__Travel__2D__g191__2D__c3259__2F__United__2D__States%3ANational__2E__Parks__2E__Monuments__2E__Etc__2E__html__2F__&pid=3825&startTime=undefined&searchSessionId=CE0A01169CA97378CAFBC24D9829C7A41481686374068ssid&sid=CE0A01169CA97378CAFBC24D9829C7A41481689024838&rf=0&sessionId=CE0A01169CA97378CAFBC24D9829C7A4&actionType=updatePage&dist=undefined&o=90&ajax=search\"\n",
    "# url_5 = \"https://www.tripadvisor.com/Search?geo=191&redirect&q=national+park&uiOrigin=MASTHEAD&ssrc=a&typeaheadRedirect=true&returnTo=__2F__Travel__2D__g191__2D__c3259__2F__United__2D__States%3ANational__2E__Parks__2E__Monuments__2E__Etc__2E__html__2F__&pid=3825&startTime=undefined&searchSessionId=CE0A01169CA97378CAFBC24D9829C7A41481686374068ssid&sid=CE0A01169CA97378CAFBC24D9829C7A41481689024838&rf=0&sessionId=CE0A01169CA97378CAFBC24D9829C7A4&actionType=updatePage&dist=undefined&o=120&ajax=search\"\n",
    "r = requests.get(url_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wannjiun/anaconda/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /Users/wannjiun/anaconda/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(r.content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = []\n",
    "for item in soup.find_all(\"div\", {\"class\": \"result ATTRACTIONS\"}):\n",
    "    #print item.contents[0].find_all(\"div\", {\"class\": \"title\"})[0].text \n",
    "    name_temp = item.contents[0].find_all(\"div\", {\"class\": \"title\"})[0].text\n",
    "    name.append(name_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review = []\n",
    "for item in soup.find_all(\"div\", {\"class\": \"result ATTRACTIONS\"}):\n",
    "    #print item.contents[0].find_all(\"a\", {\"class\": \"review-count\"})[0].text\n",
    "    review_temp = item.contents[0].find_all(\"a\", {\"class\": \"review-count\"})[0].text\n",
    "    review_temp = re.findall(\"([^\\s]+)\", review_temp) \n",
    "    review_temp = review_temp[0].strip()\n",
    "    review_temp = review_temp.replace(\",\",\"\")\n",
    "    review.append( int(review_temp) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type_attraction = []\n",
    "for item in soup.find_all(\"div\", {\"class\": \"result ATTRACTIONS\"}):\n",
    "    type_attraction_temp = item.contents[0].find_all(\"div\", {\"class\": \"type\"})[0].text\n",
    "    type_attraction.append(type_attraction_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state = []\n",
    "for item in soup.find_all(\"div\", {\"class\": \"result ATTRACTIONS\"}):\n",
    "    address_temp = item.contents[0].find_all(\"div\", {\"class\": \"address\"})[0].text\n",
    "    address_temp = address_temp.strip()\n",
    "    address_temp2 = re.findall('^.*,\\s*(.*)$', address_temp)\n",
    "    if address_temp2 == []:\n",
    "        address_temp2 = [address_temp]\n",
    "    state.append(address_temp2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "star = [0]*len(name)\n",
    "star\n",
    "for item in soup.find_all(\"div\", {\"class\": \"result ATTRACTIONS\"}):\n",
    "    #print item.contents[0].find_all(\"span\", {\"class\": \"rate rate_s s50\"})\n",
    "    item_temp = item.contents[0].find_all(\"span\", {\"class\": \"rate rate_s s50\"})\n",
    "    if item_temp != []:\n",
    "        star[i] = 5\n",
    "    item_temp = item.contents[0].find_all(\"span\", {\"class\": \"rate rate_s s45\"})\n",
    "    if item_temp != []:\n",
    "        star[i] = 4.5\n",
    "    item_temp = item.contents[0].find_all(\"span\", {\"class\": \"rate rate_s s40\"})\n",
    "    if item_temp != []:\n",
    "        star[i] = 4\n",
    "    item_temp = item.contents[0].find_all(\"span\", {\"class\": \"rate rate_s s35\"})\n",
    "    if item_temp != []:\n",
    "        star[i] = 3.5    \n",
    "    i += 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link = []\n",
    "for item in soup.find_all(\"div\", {\"class\": \"result ATTRACTIONS\"}):\n",
    "    #print item.contents[0].find_all(\"div\", {\"class\": \"title\"})[0].text \n",
    "    link_temp = item.contents[0].find_all(\"div\", {\"class\": \"title\"})[0].get('onclick')  \n",
    "    link_temp = link_temp[link_temp.find('/'):]\n",
    "    link_temp = \"https://www.tripadvisor.com\" + link_temp[:-2]\n",
    "    link.append(link_temp)\n",
    "    #print link_temp\n",
    "\n",
    "rank = []    \n",
    "for place in range(len(link)):    \n",
    "#for place in range(1):\n",
    "    r_place = requests.get(link[place]) \n",
    "    soup_place = BeautifulSoup(r_place.content) \n",
    "    for item in soup_place.find_all(\"b\", {\"class\": \"rank_text wrap\"}):\n",
    "        rank.append(int(item.contents[0].text.replace(\"#\",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "park_data = {\"name\":name,\"review\":review,\"type\":type_attraction,\"state\":state,\"star\":star,\"rank\":rank}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "park_data_frame = pd.DataFrame(park_data, columns = [\"name\",\"review\",\"type\",\"state\",\"star\",\"rank\"])\n",
    "# park_data_frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "park_data_frame.to_csv('./park_data_frame.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
